---
title: "case_study_01"
author: "Jules Stacy"
date: "January 14, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r libraries}
library(class)
library(caret)
library(e1071)
library(ggplot2)
library(tidyverse)

theme_set(
  theme_minimal()
)
```

```{r}
beer_df = read.csv("/Users/Julia/Documents/SMU/DataSci/Case Study 01/Beers.csv")
breweries_df = read.csv("/Users/Julia/Documents/SMU/DataSci/Case Study 01/Breweries.csv")

#data cleaning
colnames(breweries_df) <- c("Brewery_id", "Brewery", "City", "State")
breweries_df$State <- str_replace_all(breweries_df$State, " ", "")

#~~~debug~~~
beer_df
breweries_df
```


```{r Problem 1}
tab_1 = table(breweries_df$State)

fig_1 = ggplot(data=breweries_df) +
  geom_bar(mapping = aes(x=State, fill=State)) +
    #labels
  labs(title = "Figure 1",
       subtitle = "Number of Breweries by State",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "States",
       y = "Count of Breweries")

#Graphic Calls
tab_1
fig_1

#this table includes breweries that have multiple locations in each state
```


```{r Problem 2}
#perform merge
mbeer_orig = merge(beer_df, breweries_df, by="Brewery_id")

#duplicate beers were found, cleaning
mbeer <- mbeer_orig %>% distinct(Name, ABV, IBU, Style, Ounces, .keep_all=TRUE)

#Data was cleaned so that duplicates were removed based on name, abv, ibu, and product size in ounces

#~~~debug~~~
#beer_df$Brewery_id
#breweries_df$Brew_ID
dupes <- mbeer[duplicated(mbeer$Name),]
dupes <- dupes[order(dupes$Name),]
distinct
t_df = data.frame()
t_df
dupes
mbeer %>% filter(Name=="#9")
mbeer_orig
```


```{r Problem 3}
#Pertinent information will be kept for individual analyses:
#For analyses involving ABV, NA values for ABV will be filtered out
#For analyses involving IBU, NA values for IBU will be filtered out
#For analyses comparing IBU and ABV, NA values for either variable will be filtered out
```


```{r Custom Functions}
median_exNA<-function(input) {
   median(input[which(!is.na(input))])
}

max_exNA<-function(input) {
   max(input[which(!is.na(input))])
}
```

```{r Problem 4}




abv_state <- aggregate(ABV ~ State, mbeer, median_exNA)
ibu_state <- aggregate(IBU ~ State, mbeer, median_exNA)

#Plot: ABV by State
fig_2 = ggplot(data=abv_state, aes(x=State, y=ABV, fill=State)) +
  geom_bar(stat="identity") +
    #labels
  labs(title = "Figure 2",
       subtitle = "Median ABV by State",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "States",
       y = "Median ABV")

#Plot: IBU by State
fig_3 = ggplot(data=ibu_state, aes(x=State, y=IBU, fill=State)) +
  geom_bar(stat="identity") +
    #labels
  labs(title = "Figure 3",
       subtitle = "Median IBU by State",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "States",
       y = "Median IBU")

#~~~debug~~~
fig_3
fig_2
abv_state
mbeer %>% filter(State=="AK")

```


```{r Problem 5}
abv_max <- aggregate(ABV ~ State, mbeer, max_exNA)
ibu_max <- aggregate(IBU ~ State, mbeer, max_exNA)


#Colorado has the beer with the highest ABV at 0.128
#Oregon has the most bitter beer with an IBU of 138

#~~~debug~~~
max_exNA(mbeer$IBU)
ibu_max
```


```{r Code I want to reference later, include=off}
##Plot: ABV by State
#fig_4 = ggplot(mbeer) +
#  geom_density(aes(ABV, fill=as.factor(ABV))) +
#    #labels
#  labs(title = "Figure 4",
#       subtitle = "Distribution of ABV",
#       caption = "Source: Breweries.csv \n Author: #Jules Stacy",
#       x = "ABV",
#       y = "Percentage")
```

```{r Problem 6}
#Plot: ABV by State
fig_4 = ggplot(mbeer) +
  geom_density(aes(ABV), color="deeppink3") +
    #labels
  labs(title = "Figure 4",
       subtitle = "Distribution of ABV",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "ABV",
       y = "Percentage")


#sapply(mbeer$ABV, mean, na.rm=TRUE)
#sapply(mbeer$ABV, sd, na.rm=TRUE)
#sapply(mbeer$ABV, var, na.rm=TRUE)
#sapply(mbeer$ABV, min, na.rm=TRUE)
#sapply(mbeer$ABV, max, na.rm=TRUE)
#sapply(mbeer$ABV, median, na.rm=TRUE)
#sapply(mbeer$ABV, range, na.rm=TRUE)
#sapply(mbeer$ABV, quantile, na.rm=TRUE)


mean(mbeer$ABV[which(!is.na(mbeer$ABV))])
median(mbeer$ABV[which(!is.na(mbeer$ABV))])
sd(mbeer$ABV[which(!is.na(mbeer$ABV))])
var(mbeer$ABV[which(!is.na(mbeer$ABV))])

summary(mbeer$ABV[which(!is.na(mbeer$ABV))])

#~~debug~~
fig_4

```


```{r Problem 7}
fig_5 = ggplot(mbeer) +
  geom_point(aes(ABV, IBU), color="deeppink3") +
    #labels
  labs(title = "Figure 5",
       subtitle = "ABV Versus IBU",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "ABV",
       y = "IBU")
#~~debug~~
fig_5

```


```{r function call}
#highest_k = function(df, goalvar, column_list=c()){
#  hi_k = data.frame(accuracy = c(numeric(1000)), k = #c(numeric(1000)))
#  for (j in 1:1000) {
#    #find the optimal k value to test
#    accs = data.frame(accuracy = numeric(30), k = #numeric(30))
#
#    for(i in 1:30){
#      predict = knn.cv(df[,column_list], goalvar, #prob=TRUE, k=i)
#      predict_check = table(goalvar,predict)
#      CM = confusionMatrix(predict_check)
#      accs$accuracy[i] = CM$overall[1]
#      accs$k[i] = i
#}
#
#    hi_k[j,] = accs[which.max(accs$accuracy),]
#}
#
#
#  plot(accs$k,accs$accuracy, type = "l", xlab = "k")
#
#}


#-------------------------------------
#-----define parameters-----
kmax=90
loops=100
hyperparameter_k <- function(kmax=90, loops=100, train, test, full){
accs1 = data.frame(k = numeric(kmax), accuracy = numeric(kmax), accuracy2=numeric(kmax))
accs2 = data.frame(k = numeric(kmax), accuracy = numeric(kmax), accuracy2=numeric(kmax))

#-----define loop-----
#housed processes to speed compile time
#each loop processes train vs test and then icv
for(j in 1:loops){
for(i in 1:kmax)
{
  classifications1 = knn(train[,c(1,2)],test[,c(1,2)],train[,3], prob = TRUE, k = i)
  sur1 = table(test[,3],classifications1)
  CM1 = confusionMatrix(sur1)
  accs1$accuracy[i] = accs1$accuracy[i] + CM1$overall[1]
  accs1$k[i] = i
  
  classifications2 = knn.cv(full[,c(1,2)], full[,3], prob=TRUE, k=i)
  sur2 = table(full[,3],classifications2)
  CM2 = confusionMatrix(sur2)
  accs2$accuracy[i] = accs2$accuracy[i] + CM2$overall[1]
  accs2$k[i] = i
  
  }
}

#finish the calculation of averages
accs1$accuracy <- accs1$accuracy/loops
accs2$accuracy <- accs2$accuracy/loops

accs <- merge(accs1$accuracy, accs2$accuracy)

#-----build plots-----
p1 <- ggplot(data=accs1, aes(x=k, y=accuracy)) +
  geom_point() +
  geom_text(aes(label=accs1$k), hjust=-.2, size=2.7)+
  labs(title = "Scatterplot: Hyperparameter K Average Accuracies",
       subtitle = "500 Iterations Using Train and Test Data",
       caption = "Source: Iris Dataset \nAuthor: Jules Stacy",
       x = "Hyperparameter K",
       y = "Average Accuracy")

p2 <- ggplot(data=accs2, aes(x=k, y=accuracy)) +
  geom_point() +
  geom_text(aes(label=accs2$k), hjust=-.2, size=2.7)+
  labs(title = "Scatterplot: Hyperparameter K Average Accuracies",
       subtitle = "500 Iterations Using Leave One Out Cross-Validation",
       caption = "Source: Iris Dataset \nAuthor: Jules Stacy",
       x = "Hyperparameter K",
       y = "Average Accuracy")
}
#------------------------------------
```


```{r Problem 8.1}




mbeer$isipa <- as.numeric(str_detect(mbeer$Style, "IPA"))
mbeer$isale <- as.numeric(str_detect(mbeer$Style, "Ale"))
names(mbeer$isipa) <- "is_IPA"
names(mbeer$isale) <- "is_Ale"

ipa_g <- mbeer %>% filter(mbeer$isipa == 1)
ale_g <- mbeer %>% filter(mbeer$isale==1)

ipa_g$isipa <- "IPA"
ale_g$isipa <- "Ale"


ipa_g <- ipa_g[,c(4, 5, 11)]
ale_g <- ale_g[,c(4, 5, 11)]
beer_g <- merge(ipa_g, ale_g, all=TRUE)
beer_g <- beer_g[complete.cases(beer_g),]
beer_g$isipa <- as.factor(beer_g$isipa)


fig_6 <- ggplot(beer_g, aes(x=IBU, y=ABV)) +
  geom_point(aes(color=beer_g$isipa)) +
  labs(title = "Figure 6",
       subtitle = "IBU Versus ABV, Colored by Beer Type",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "IBU",
       y = "ABV")

#~~debug~~
fig_6
ipa_g
```


```{r Problem 8.2}
#beer_k is now a list of IPAs and Ales with ABV values, IBU values, and no NA values. Now it's time to develop a training and test set. Training set taken from cleaned data
mbeer$isipa <- as.numeric(str_detect(mbeer$Style, "IPA"))
mbeer$isale <- as.numeric(str_detect(mbeer$Style, "Ale"))

ipa_k <- mbeer %>% filter(mbeer$isipa == 1)
ale_k <- mbeer %>% filter(mbeer$isale==1)

ipa_k <- ipa_k[,c(4, 5, 11)]
ale_k <- ale_k[,c(4, 5, 11)]
beer_k <- merge(ipa_k, ale_k, all=TRUE)
beer_k <- beer_k[complete.cases(beer_k),]
beer_k$isipa <- as.factor(beer_k$isipa)

train <- beer_k[sample(nrow(beer_k), size=311),]
test <- setdiff(beer_k, train)

#--------------HYPERPARAMETER K TESTING--------------
#-----define parameters-----
kmax=90
loops=100
accs1 = data.frame(k = numeric(kmax), accuracy = numeric(kmax), accuracy2=numeric(kmax))
accs2 = data.frame(k = numeric(kmax), accuracy = numeric(kmax), accuracy2=numeric(kmax))

#-----define loop-----
#housed processes to speed compile time
#each loop processes train vs test and then icv
for(j in 1:loops){
for(i in 1:kmax)
{
  classifications1 = knn(train[,c(1,2)],test[,c(1,2)],train[,3], prob = TRUE, k = i)
  sur1 = table(test[,3],classifications1)
  CM1 = confusionMatrix(sur1)
  accs1$accuracy[i] = accs1$accuracy[i] + CM1$overall[1]
  accs1$k[i] = i
  
  classifications2 = knn.cv(beer_k[,c(1,2)], beer_k[,3], prob=TRUE, k=i)
  sur2 = table(beer_k[,3],classifications2)
  CM2 = confusionMatrix(sur2)
  accs2$accuracy[i] = accs2$accuracy[i] + CM2$overall[1]
  accs2$k[i] = i
  
  }
}

#finish the calculation of averages
accs1$accuracy <- accs1$accuracy/loops
accs2$accuracy <- accs2$accuracy/loops

#-----build plots-----
fig_7 <- ggplot(data=accs1, aes(x=k, y=accuracy)) +
  geom_point() +
  geom_text(aes(label=accs1$k), hjust=-.2, size=2.7)+
  labs(title = "Figure 7",
       subtitle = "Train and Test Hyperparameter K: 100 Iterations",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "Hyperparameter K",
       y = "Average Accuracy")

fig_8 <- ggplot(data=accs2, aes(x=k, y=accuracy)) +
  geom_point() +
  geom_text(aes(label=accs2$k), hjust=-.2, size=2.7)+
  labs(title = "Figure 8",
       subtitle = "Leave One Out Hyperparameter K: 100 Iterations",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "Hyperparameter K",
       y = "Average Accuracy")

#------------------------------------
#the best k for train-and-test is 19
#the best k for leave-one-out is 8

classifications1 = knn(train[,c(1,2)],test[,c(1,2)],train[,3], prob = TRUE, k = 18)
sur1 = table(test[,3],classifications1)
CM1 = confusionMatrix(sur1)


#~~debug~~
CM1
fig_7
fig_8
beer_k
train
test
mbeer
```


```{r Problem 8.3}

#code for test and train
classifications1 = knn(train[,c(1,2)],test[,c(1,2)],train[,3], prob = TRUE, k = i)
  sur1 = table(test[,3],classifications1)
  CM1 = confusionMatrix(sur1)

```{r}